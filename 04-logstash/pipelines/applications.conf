input {
  beats {
    port => 5044
  }
  
  kafka {
    bootstrap_servers => "kafka:9092"
    topics => ["logs", "metrics", "events"]
    codec => "json"
  }
}

filter {
  if [fields][service] {
    mutate {
      add_field => { "service_name" => "%{[fields][service]}" }
    }
  }
  
  if [message] =~ /ERROR/ {
    mutate {
      add_tag => ["error"]
      add_field => { "log_level" => "error" }
    }
  } else if [message] =~ /WARN/ {
    mutate {
      add_tag => ["warning"]
      add_field => { "log_level" => "warning" }
    }
  } else {
    mutate {
      add_field => { "log_level" => "info" }
    }
  }
  
  # Parse nginx logs
  if [fields][log_type] == "nginx" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
    }
    
    mutate {
      convert => { "response" => "integer" }
      convert => { "bytes" => "integer" }
    }
  }
  
  # Add timestamp
  mutate {
    add_field => { "processed_at" => "%{@timestamp}" }
  }
}

output {
  # Route different log types to different indices
  if [fields][service] == "order-service" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "orders-%{+YYYY.MM.dd}"
    }
  } else if [fields][service] == "product-service" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "products-%{+YYYY.MM.dd}"
    }
  } else if [fields][service] == "user-service" {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "users-%{+YYYY.MM.dd}"
    }
  } else {
    elasticsearch {
      hosts => ["http://elasticsearch:9200"]
      index => "logs-%{+YYYY.MM.dd}"
    }
  }
  
  # Debug output
  if [fields][debug] {
    stdout {
      codec => rubydebug
    }
  }
}
